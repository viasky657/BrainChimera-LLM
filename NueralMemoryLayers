import torch
import torch.nn as nn
import time
import pickle
from collections import OrderedDict
import uuid

class MemoryNode:
    def __init__(self, memory_chunk, timestamp, centroid=None):
        self.id = uuid.uuid4()  # Generate a unique ID
        self.memory_chunk = memory_chunk
        self.timestamp = timestamp
        self.centroid = centroid
        self.children = []

    def get_num_memories(self):
        if not self.children:
            return 1
        
        total_memories = 0
        for child in self.children:
            total_memories += child.get_num_memories()
            
        return total_memories

class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = OrderedDict()

    def get(self, key):
        if key not in self.cache:
            return None
        else:
            self.cache.move_to_end(key)  # Move accessed item to the end
            return self.cache[key]

    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)  # Move updated item to the end
        self.cache[key] = value
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)  # Remove least recently used item (from the beginning)

class HierarchicalMemory:
    def __init__(self, num_layers, root_memory_chunk_size, cache_capacity=10000):
        self.num_layers = num_layers  # Number of memory layers is now a parameter
        self.root_memory_chunk_size = root_memory_chunk_size
        self.cache_capacity = cache_capacity
        self.active_layer = 0

        # Create memory layers dynamically
        self.memory_layers = [self._create_memory_layer() for _ in range(self.num_layers)]
        self.surprise_layers = [self._create_memory_layer() for _ in range(self.num_layers)]

        self._similarity_cache = LRUCache(self.cache_capacity)
      
    def traverse(self, key, similarity_threshold, create_threshold):
        """
        Traverses the hierarchical memory to find the most relevant node for a given key.

        Args:
            key: The input key (a PyTorch tensor).
            similarity_threshold: The minimum similarity required to consider a node relevant.
            create_threshold: The minimum similarity required to create a new child node.

        Returns:
            A tuple: (current_node, surprise_node) 
                - current_node: The MemoryNode that is most relevant to the key.
                - surprise_node: The corresponding node in the surprise hierarchy.
        """
        current_node = self.root
        surprise_node = self.surprise_root  # Assuming a parallel surprise hierarchy

        while True:
            if not current_node.children:  # If the current node is a leaf node
                if torch.dot(key, current_node.centroid) < create_threshold:
                    # Create a new child node
                    new_child = MemoryNode(current_node.memory_chunk.shape, time.time(), centroid=key)
                    new_surprise_child = MemoryNode(current_node.memory_chunk.shape, time.time())  # Assuming you initialize surprise with zeros
                    current_node.children.append(new_child)
                    surprise_node.children.append(new_surprise_child)
                    return new_child, new_surprise_child
                else:
                    return current_node, surprise_node

            # Find the most similar child
            most_similar_child = None
            most_similar_surprise_child = None
            highest_similarity = -float('inf')

            for i, child in enumerate(current_node.children):
                similarity = torch.dot(key, child.centroid)  # Cosine similarity
                if similarity > highest_similarity:
                    highest_similarity = similarity
                    most_similar_child = child
                    most_similar_surprise_child = surprise_node.children[i]

            # Decide whether to move to a child or stay at the current node
            if highest_similarity >= similarity_threshold:
                current_node = most_similar_child
                surprise_node = most_similar_surprise_child
            else:
                if torch.dot(key, current_node.centroid) < create_threshold:
                    # Create a new child node under the current node
                    new_child = MemoryNode(current_node.memory_chunk.shape, time.time(), centroid=key)
                    new_surprise_child = MemoryNode(current_node.memory_chunk.shape, time.time())
                    current_node.children.append(new_child)
                    surprise_node.children.append(new_surprise_child)
                    return new_child, new_surprise_child
                else:
                    return current_node, surprise_node

   
    def merge_nodes(self, node1, node2):
        """
        Merges two memory nodes into a single new node, weighting the average by the inverse
        of the timestamps to give more weight to recent memories.

        Args:
            node1: The first MemoryNode to merge.
            node2: The second MemoryNode to merge.

        Returns:
            The new merged MemoryNode.
        """
        # 1. Calculate weights based on the inverse of timestamps:
        #    - Avoid division by zero (handle cases where timestamp is very small).
        #    - Normalize weights to sum to 1.
        epsilon = 1e-10  # Small value to avoid division by zero
        weight1 = 1 / (node1.timestamp + epsilon)
        weight2 = 1 / (node2.timestamp + epsilon)
        total_weight = weight1 + weight2
        weight1 /= total_weight
        weight2 /= total_weight

        # 2. Create a new memory chunk by weighted averaging:
        new_memory_chunk = (node1.memory_chunk * weight1 + node2.memory_chunk * weight2)

        # 3. Set the timestamp of the new node using weighted averaging:
        new_timestamp = (node1.timestamp * weight1 + node2.timestamp * weight2)

        # 4. Set the centroid of the new node using weighted averaging:
        new_centroid = (node1.centroid * weight1 + node2.centroid * weight2)

        # 5. Create the new merged node.
        new_node = MemoryNode(new_memory_chunk, new_timestamp, new_centroid)

        # 6. Make the children of the two merged nodes the children of the new node.
        new_node.children = node1.children + node2.children

        return new_node

       def merge_similar_nodes(self, similarity_threshold):
        """
        Recursively merges similar nodes in the memory hierarchy, including the surprise hierarchy.
        Uses an LRU cache with unique node IDs for efficiency.
        """
        self._similarity_cache = LRUCache(self.cache_capacity)  # Initialize LRU cache
        self._merge_similar_nodes_recursive(self.root, self.surprise_root, similarity_threshold)
        self._similarity_cache = LRUCache(self.cache_capacity)  # Clear the cache (reinitialize)

    def activate_next_layer(self):
        """Activates the next memory layer if available."""
        if self.active_layer < self.num_layers - 1:
            self.active_layer += 1
            self._similarity_cache = LRUCache(self.cache_capacity)  # Initialize cache for the new layer
            print(f"Activated memory layer: {self.active_layer}")
        else:
            print("All memory layers are active.")

    def is_layer_full(self, threshold_factor=0.8):
        """
        Checks if the active memory layer is considered full based on a threshold factor.
        """
        active_memory_root = self.memory_layers[self.active_layer]
        active_surprise_root = self.surprise_layers[self.active_layer]

        num_nodes = self._count_nodes(active_memory_root)
        num_non_empty_nodes = self._count_non_empty_nodes(active_memory_root)

        return num_non_empty_nodes / num_nodes >= threshold_factor

   def merge_similar_nodes(self, similarity_threshold):
        """
        Recursively merges similar nodes in the active memory layer.
        """
        active_memory_root = self.memory_layers[self.active_layer]
        active_surprise_root = self.surprise_layers[self.active_layer] #Last change was here. Last left off with adding parameter memory layers. Near the top of the list of changes. 

        if not node.children:
            return

        # 1. Recursively merge similar nodes in the children
        for i in range(len(node.children)):
            self._merge_similar_nodes_recursive(node.children[i], surprise_node.children[i], similarity_threshold)

        # 2. Compare children of the current node (with caching)
        merged = [False] * len(node.children)
        for i in range(len(node.children)):
            if merged[i]:
                continue
            for j in range(i + 1, len(node.children)):
                if merged[j]:
                    continue

                # Get similarity from LRU cache or calculate it (using node IDs)
                node_pair = tuple(sorted((node.children[i].id, node.children[j].id)))
                similarity = self._similarity_cache.get(node_pair)  # Use get() from LRU cache
                if similarity is None:
                    similarity = torch.dot(node.children[i].centroid, node.children[j].centroid)
                    self._similarity_cache.put(node_pair, similarity)  # Use put() for LRU cache

  def save(self, filepath):
        """
        Saves the hierarchical memory to a file.

        Args:
            filepath: The path to the file where the memory will be saved.
        """
        # Don't save the cache
        cache_holder = self._similarity_cache
        self._similarity_cache = None

        with open(filepath, 'wb') as f:
            pickle.dump(self, f)

        # Restore the cache
        self._similarity_cache = cache_holder

    @staticmethod
    def load(filepath, cache_capacity=10000):
        """
        Loads a hierarchical memory from a file.

        Args:
            filepath: The path to the file from which the memory will be loaded.
            cache_capacity: The capacity for the new LRU cache.

        Returns:
            The loaded HierarchicalMemory object.
        """
        with open(filepath, 'rb') as f:
            loaded_memory = pickle.load(f)

        # Generate new unique IDs for all nodes
        def regenerate_ids(node):
            node.id = uuid.uuid4()
            for child in node.children:
                regenerate_ids(child)

        regenerate_ids(loaded_memory.root)
        regenerate_ids(loaded_memory.surprise_root)  # Regenerate IDs for the surprise hierarchy as well

        # Initialize a new LRU cache
        loaded_memory._similarity_cache = LRUCache(cache_capacity)

        return loaded_memory

class NeuralMemory(nn.Module):
    def __init__(self, input_size, memory_size, forgetting_list, beta, similarity_threshold, create_threshold, alpha, eta, theta):
        super().__init__()
        # ... (Define W_K, W_V, W_O, memory, etc.) ...
        self.memory = HierarchicalMemory(memory_size)
        self.forgetting_list = forgetting_list
        self.beta = beta
        self.similarity_threshold = similarity_threshold
        self.create_threshold = create_threshold
        self.alpha = alpha
        self.eta = eta
        self.theta = theta

    def forward(self, x_t, memory_state):
        # ... (Implementation of the enhanced NeuralMemory algorithm) ...
        memory_output, updated_memory_state, updated_surprise_state = self.neural_memory(x_t, memory_state, surprise_state)
        # ... (key, value projection) ...
        current_memory_node, current_surprise_node = self.memory.traverse(key, self.similarity_threshold, self.create_threshold)
        # current_memory_node now holds the relevant memory chunk
        # current_surprise_node now holds the corresponding surprise chunk

        # ... (Use current_memory_node.memory_chunk for surprise calculation and memory retrieval) ...
        # ... (Update current_memory_node.memory_chunk and current_surprise_node.memory_chunk) ...
        # ... (Update centroid, timestamp, etc.) ...

       # Create a hierarchical memory with 3 layers
        memory = HierarchicalMemory(num_layers=3, root_memory_chunk_size=(100, 50))

        # ... (Interact with the memory, add data, etc.) ...

        # Check if the active layer is full (and activate the next layer if needed)
        if memory.is_layer_full():
            memory.activate_next_layer()

        # ... (Continue interacting with the memory, merging nodes, etc.) ...

        # Save the memory
        memory.save("my_multi_layered_memory.pickle")

        # Load the memory later
        loaded_memory = HierarchicalMemory.load("my_multi_layered_memory.pickle")
        # Save the memory
        memory.save("my_memory.pickle")

        # Load the memory later
        loaded_memory = HierarchicalMemory.load("my_memory.pickle", cache_capacity=5000)

        # Continue using the loaded memory
        # ... (Perform merging, etc.) ...

class MAG(nn.Module):
    def __init__(self, input_size, memory_size, persistent_memory_size, forgetting_list, beta, similarity_threshold, create_threshold, alpha, eta, theta):
        super().__init__()
        # ... (Define SWA, NeuralMemory, gating mechanism, etc.) ...
        self.neural_memory = NeuralMemory(input_size, memory_size, forgetting_list, beta, similarity_threshold, create_threshold, alpha, eta, theta)
        self.persistent_memory = nn.Parameter(torch.randn(persistent_memory_size))

    def forward(self, x):
        # ... (Implementation of the MAG algorithm with hierarchical memory) ...
